{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_NODE = 784\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "LAYER1_NODE = 500\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "LEARNING_RATE_BASE = 0.8\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "REGULARAZTION_RATE = 0.0001\n",
    "TRAINING_STEPS = 30000\n",
    "MOVING_AVERAGE_DECAY = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "    else:\n",
    "        layer2 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + \n",
    "                               avg_class.average(biases1))\n",
    "        return tf.matmul(layer2, avg_class.average(weights2)) + avg_class.average(biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(mnist):\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name = 'x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name = 'y-input')\n",
    "    \n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev = 0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape = [LAYER1_NODE]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev = 0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape = [OUTPUT_NODE]))\n",
    "    \n",
    "    y = inference(x, None, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable = False)\n",
    "    \n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        MOVING_AVERAGE_DECAY, global_step)\n",
    "    \n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "       logits=y, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n",
    "    regularization  = regularizer(weights1) + regularizer(weights2)\n",
    "    loss = cross_entropy_mean + regularization \n",
    "    #上一行找了半天的bug 失之毫厘谬以千里 注意英文拼写！！！！！ 在打loss的时候打成了cross_entropy！！ 细心\n",
    "    \n",
    "    # 设置指数衰减的学习率。\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        mnist.train.num_examples / BATCH_SIZE,\n",
    "        LEARNING_RATE_DECAY,\n",
    "        staircase=True)\n",
    "    \n",
    "    # 优化损失函数\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "        train_op = tf.no_op(name = 'train')\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        validate_feed = {x : mnist.validation.images,\n",
    "                         y_: mnist.validation.labels}\n",
    "        \n",
    "        test_feed = {x : mnist.test.images,\n",
    "                     y_: mnist.test.labels}\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict = validate_feed)\n",
    "                print(\"After %d step(s), validation accuracy \"\n",
    "                     \"using average model is %g \" % (i ,validate_acc))\n",
    "                \n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict = {x :xs, y_:ys})\n",
    "            \n",
    "        test_acc=sess.run(accuracy,feed_dict=test_feed)\n",
    "        print((\"After %d training step(s), test accuracy using average model is %g\" %(TRAINING_STEPS, test_acc)))\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/visit/learn_tf/ch5/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /home/visit/learn_tf/ch5/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/visit/learn_tf/ch5/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/visit/learn_tf/ch5/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/home/visit/learn_tf/ch5/mnist\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 step(s), validation accuracy using average model is 0.0956 \n",
      "After 1000 step(s), validation accuracy using average model is 0.9766 \n",
      "After 2000 step(s), validation accuracy using average model is 0.9816 \n",
      "After 3000 step(s), validation accuracy using average model is 0.9838 \n",
      "After 4000 step(s), validation accuracy using average model is 0.9838 \n",
      "After 5000 step(s), validation accuracy using average model is 0.985 \n",
      "After 6000 step(s), validation accuracy using average model is 0.9848 \n",
      "After 7000 step(s), validation accuracy using average model is 0.986 \n",
      "After 8000 step(s), validation accuracy using average model is 0.984 \n",
      "After 9000 step(s), validation accuracy using average model is 0.9844 \n",
      "After 10000 step(s), validation accuracy using average model is 0.9856 \n",
      "After 11000 step(s), validation accuracy using average model is 0.9852 \n",
      "After 12000 step(s), validation accuracy using average model is 0.985 \n",
      "After 13000 step(s), validation accuracy using average model is 0.9852 \n",
      "After 14000 step(s), validation accuracy using average model is 0.9852 \n",
      "After 15000 step(s), validation accuracy using average model is 0.985 \n",
      "After 16000 step(s), validation accuracy using average model is 0.9852 \n",
      "After 17000 step(s), validation accuracy using average model is 0.9852 \n",
      "After 18000 step(s), validation accuracy using average model is 0.985 \n",
      "After 19000 step(s), validation accuracy using average model is 0.985 \n",
      "After 20000 step(s), validation accuracy using average model is 0.9856 \n",
      "After 21000 step(s), validation accuracy using average model is 0.9862 \n",
      "After 22000 step(s), validation accuracy using average model is 0.9852 \n",
      "After 23000 step(s), validation accuracy using average model is 0.9856 \n",
      "After 24000 step(s), validation accuracy using average model is 0.9852 \n",
      "After 25000 step(s), validation accuracy using average model is 0.9848 \n",
      "After 26000 step(s), validation accuracy using average model is 0.986 \n",
      "After 27000 step(s), validation accuracy using average model is 0.985 \n",
      "After 28000 step(s), validation accuracy using average model is 0.9852 \n",
      "After 29000 step(s), validation accuracy using average model is 0.9856 \n",
      "After 30000 training step(s), test accuracy using average model is 0.9843\n"
     ]
    }
   ],
   "source": [
    "train(mnist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
